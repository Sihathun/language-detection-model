{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2467ebd",
   "metadata": {},
   "source": [
    "## Import stuff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instructional-import",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-04-09T10:01:50.209379Z",
     "iopub.status.busy": "2021-04-09T10:01:50.208612Z",
     "iopub.status.idle": "2021-04-09T10:01:52.592191Z",
     "shell.execute_reply": "2021-04-09T10:01:52.593326Z"
    },
    "papermill": {
     "duration": 2.411063,
     "end_time": "2021-04-09T10:01:52.593671",
     "exception": false,
     "start_time": "2021-04-09T10:01:50.182608",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dataset.csv']\n",
      "Example:\n",
      "LANG = Estonian\n",
      "TEXT = klement gottwaldi surnukeha palsameeriti ning paigutati mausoleumi surnukeha oli aga liiga hilja ja oskamatult palsameeritud ning hakkas ilmutama lagunemise tundemÃ¤rke  aastal viidi ta surnukeha mausoleumist Ã¤ra ja kremeeriti zlÃ­ni linn kandis aastatel â nime gottwaldov ukrainas harkivi oblastis kandis zmiivi linn aastatel â nime gotvald\n",
      "Example:\n",
      "LANG = Estonian\n",
      "TEXT = klement gottwaldi surnukeha palsameeriti ning paigutati mausoleumi surnukeha oli aga liiga hilja ja oskamatult palsameeritud ning hakkas ilmutama lagunemise tundemÃ¤rke  aastal viidi ta surnukeha mausoleumist Ã¤ra ja kremeeriti zlÃ­ni linn kandis aastatel â nime gottwaldov ukrainas harkivi oblastis kandis zmiivi linn aastatel â nime gotvald\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "import os\n",
    "INPUTDIR = '../input/language-identification-datasst'\n",
    "print(os.listdir(f'{INPUTDIR}'))\n",
    "\n",
    "#Init random seed to get reproducible results\n",
    "seed = 1111\n",
    "random.seed(seed)\n",
    "np.random.RandomState(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# Any results you write to the current directory are saved as output.\n",
    "raw = pd.read_csv(f'{INPUTDIR}/dataset.csv', encoding='latin-1')\n",
    "x_train_full = raw['Text']\n",
    "y_train_full = raw['language']\n",
    "print('Example:')\n",
    "print('LANG =', y_train_full[0])\n",
    "print('TEXT =', x_train_full[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babf7ca0",
   "metadata": {},
   "source": [
    "## Define the Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "tracked-power",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2021-04-09T10:01:52.650408Z",
     "iopub.status.busy": "2021-04-09T10:01:52.649558Z",
     "iopub.status.idle": "2021-04-09T10:01:52.653389Z",
     "shell.execute_reply": "2021-04-09T10:01:52.653997Z"
    },
    "papermill": {
     "duration": 0.03524,
     "end_time": "2021-04-09T10:01:52.654197",
     "exception": false,
     "start_time": "2021-04-09T10:01:52.618957",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Dictionary(object):\n",
    "    def __init__(self):\n",
    "        self.token2idx = {}\n",
    "        self.idx2token = []\n",
    "\n",
    "    def add_token(self, token):\n",
    "        if token not in self.token2idx:\n",
    "            self.idx2token.append(token)\n",
    "            self.token2idx[token] = len(self.idx2token) - 1\n",
    "        return self.token2idx[token]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idx2token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "annoying-trust",
   "metadata": {
    "papermill": {
     "duration": 0.022557,
     "end_time": "2021-04-09T10:01:52.699652",
     "exception": false,
     "start_time": "2021-04-09T10:01:52.677095",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The **Dictionary** class is used to map tokens (characters, words, subwords) into consecutive integer indexes.  \n",
    "The index **0** is reserved for padding sequences up to a fixed lenght, and the index **1** for any 'unknown' character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "excited-makeup",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-09T10:01:53.107415Z",
     "iopub.status.busy": "2021-04-09T10:01:53.106520Z",
     "iopub.status.idle": "2021-04-09T10:01:53.110180Z",
     "shell.execute_reply": "2021-04-09T10:01:53.110784Z"
    },
    "papermill": {
     "duration": 0.38017,
     "end_time": "2021-04-09T10:01:53.111008",
     "exception": false,
     "start_time": "2021-04-09T10:01:52.730838",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: 153 UTF characters\n",
      "Labels: 22 languages\n"
     ]
    }
   ],
   "source": [
    "char_vocab = Dictionary()\n",
    "pad_token = '<pad>' # reserve index 0 for padding\n",
    "unk_token = '<unk>' # reserve index 1 for unknown token\n",
    "pad_index = char_vocab.add_token(pad_token)\n",
    "unk_index = char_vocab.add_token(unk_token)\n",
    "\n",
    "# join all the training sentences in a single string\n",
    "# and obtain the list of different characters with set\n",
    "chars = set(''.join(x_train_full))\n",
    "for char in sorted(chars):\n",
    "    char_vocab.add_token(char)\n",
    "print(\"Vocabulary:\", len(char_vocab), \"UTF characters\")\n",
    "\n",
    "lang_vocab = Dictionary()\n",
    "# use python set to obtain the list of languages without repetitions\n",
    "languages = set(y_train_full)\n",
    "for lang in sorted(languages):\n",
    "    lang_vocab.add_token(lang)\n",
    "print(\"Labels:\", len(lang_vocab), \"languages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dafa7c0",
   "metadata": {},
   "source": [
    "### Convert Text and Labels to Integer Indices\n",
    "Map each character in the text samples to its vocabulary index, and each language label to its corresponding index. This transforms the raw text data into numerical format suitable for the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "daily-immigration",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-09T10:01:53.191060Z",
     "iopub.status.busy": "2021-04-09T10:01:53.180739Z",
     "iopub.status.idle": "2021-04-09T10:01:55.659944Z",
     "shell.execute_reply": "2021-04-09T10:01:55.660714Z"
    },
    "papermill": {
     "duration": 2.533233,
     "end_time": "2021-04-09T10:01:55.660929",
     "exception": false,
     "start_time": "2021-04-09T10:01:53.127696",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k -> 26\n",
      "Estonian -> 4\n",
      "Estonian klement go\n",
      "4 [26 27 20 28 20 29 35  2 22 30]\n",
      "4 [26 27 20 28 20 29 35  2 22 30]\n"
     ]
    }
   ],
   "source": [
    "#From token or label to index\n",
    "print('k ->', char_vocab.token2idx['k'])\n",
    "print('Estonian ->', lang_vocab.token2idx['Estonian'])\n",
    "print(y_train_full[0], x_train_full[0][:10])\n",
    "x_train_idx = [np.array([char_vocab.token2idx[c] for c in line]) for line in x_train_full]\n",
    "y_train_idx = np.array([lang_vocab.token2idx[lang] for lang in y_train_full])\n",
    "print(y_train_idx[0], x_train_idx[0][:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spare-artwork",
   "metadata": {
    "papermill": {
     "duration": 0.015729,
     "end_time": "2021-04-09T10:01:55.692528",
     "exception": false,
     "start_time": "2021-04-09T10:01:55.676799",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Radomly select 20% of the database for validation  \n",
    "Create lists of (input, target) tuples for training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "advanced-pittsburgh",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-09T10:01:55.732296Z",
     "iopub.status.busy": "2021-04-09T10:01:55.731608Z",
     "iopub.status.idle": "2021-04-09T10:01:56.952002Z",
     "shell.execute_reply": "2021-04-09T10:01:56.952493Z"
    },
    "papermill": {
     "duration": 1.242636,
     "end_time": "2021-04-09T10:01:56.952654",
     "exception": false,
     "start_time": "2021-04-09T10:01:55.710018",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17600 training samples\n",
      "4400 validation samples\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train_idx, y_train_idx, test_size=0.2, random_state=42)\n",
    "train_data = [(x, y) for x, y in zip(x_train, y_train)]\n",
    "val_data = [(x, y) for x, y in zip(x_val, y_val)]\n",
    "print(len(train_data), \"training samples\")\n",
    "print(len(val_data), \"validation samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "concerned-judge",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-09T10:01:56.993984Z",
     "iopub.status.busy": "2021-04-09T10:01:56.993263Z",
     "iopub.status.idle": "2021-04-09T10:01:56.996358Z",
     "shell.execute_reply": "2021-04-09T10:01:56.995899Z"
    },
    "papermill": {
     "duration": 0.026961,
     "end_time": "2021-04-09T10:01:56.996482",
     "exception": false,
     "start_time": "2021-04-09T10:01:56.969521",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def batch_generator(data, batch_size, token_size):\n",
    "    \"\"\"Yield elements from data in chunks with a maximum of batch_size sequences and token_size tokens.\"\"\"\n",
    "    minibatch, sequences_so_far, tokens_so_far = [], 0, 0\n",
    "    for ex in data:\n",
    "        seq_len = len(ex[0])\n",
    "        if seq_len > token_size:\n",
    "            ex = (ex[0][:token_size], ex[1])\n",
    "            seq_len = token_size\n",
    "        minibatch.append(ex)\n",
    "        sequences_so_far += 1\n",
    "        tokens_so_far += seq_len\n",
    "        if sequences_so_far == batch_size or tokens_so_far == token_size:\n",
    "            yield minibatch\n",
    "            minibatch, sequences_so_far, tokens_so_far = [], 0, 0\n",
    "        elif sequences_so_far > batch_size or tokens_so_far > token_size:\n",
    "            yield minibatch[:-1]\n",
    "            minibatch, sequences_so_far, tokens_so_far = minibatch[-1:], 1, len(minibatch[-1][0])\n",
    "    if minibatch:\n",
    "        yield minibatch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb9ed3c",
   "metadata": {},
   "source": [
    "### Batch Generator\n",
    "Creates mini-batches of data with constraints on both the number of sequences (`batch_size`) and total tokens (`token_size`). Sequences longer than `token_size` are truncated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "violent-response",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-09T10:01:57.036153Z",
     "iopub.status.busy": "2021-04-09T10:01:57.035353Z",
     "iopub.status.idle": "2021-04-09T10:01:57.038197Z",
     "shell.execute_reply": "2021-04-09T10:01:57.038587Z"
    },
    "papermill": {
     "duration": 0.026167,
     "end_time": "2021-04-09T10:01:57.038729",
     "exception": false,
     "start_time": "2021-04-09T10:01:57.012562",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pool_generator(data, batch_size, token_size, shuffle=False):\n",
    "    \"\"\"Sort within buckets, then batch, then shuffle batches.\n",
    "    Partitions data into chunks of size 100*token_size, sorts examples within\n",
    "    each chunk, then batch these examples and shuffle the batches.\n",
    "    \"\"\"\n",
    "    for p in batch_generator(data, batch_size * 100, token_size * 100):\n",
    "        p_batch = batch_generator(sorted(p, key=lambda t: len(t[0]), reverse=True), batch_size, token_size)\n",
    "        p_list = list(p_batch)\n",
    "        if shuffle:\n",
    "            for b in random.sample(p_list, len(p_list)):\n",
    "                yield b\n",
    "        else:\n",
    "            for b in p_list:\n",
    "                yield b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6536cfd",
   "metadata": {},
   "source": [
    "### Pool Generator (Bucketed Batching)\n",
    "Sorts sequences by length within buckets for efficient padding, then creates batches and optionally shuffles them. This minimizes wasted computation from padding shorter sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colored-giving",
   "metadata": {
    "papermill": {
     "duration": 0.016458,
     "end_time": "2021-04-09T10:01:57.071705",
     "exception": false,
     "start_time": "2021-04-09T10:01:57.055247",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**DNN Model**  \n",
    "Includes Python comments with the dimension of the input  matrix:  \n",
    "T = Max number of tokens in a sequence  \n",
    "B = Number of sequences (batch size)  \n",
    "E = Embedding dim  \n",
    "H = Hidden size  \n",
    "O = Output size (number of languages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "brown-scott",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-09T10:01:57.115135Z",
     "iopub.status.busy": "2021-04-09T10:01:57.114263Z",
     "iopub.status.idle": "2021-04-09T10:01:57.117643Z",
     "shell.execute_reply": "2021-04-09T10:01:57.117081Z"
    },
    "papermill": {
     "duration": 0.029294,
     "end_time": "2021-04-09T10:01:57.117774",
     "exception": false,
     "start_time": "2021-04-09T10:01:57.088480",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CharRNNClassifier(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, output_size, model=\"lstm\", num_layers=1, bidirectional=False, pad_idx=0):\n",
    "        super().__init__()\n",
    "        self.model = model.lower()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embed = torch.nn.Embedding(input_size, embedding_size, padding_idx=pad_idx)\n",
    "        if self.model == \"gru\":\n",
    "            self.rnn = torch.nn.GRU(embedding_size, hidden_size, num_layers, bidirectional=bidirectional)\n",
    "        elif self.model == \"lstm\":\n",
    "            self.rnn = torch.nn.LSTM(embedding_size, hidden_size, num_layers, bidirectional=bidirectional)\n",
    "        self.h2o = torch.nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, input, input_lengths):\n",
    "        # T x B\n",
    "        encoded = self.embed(input)\n",
    "        # T x B x E\n",
    "        packed = torch.nn.utils.rnn.pack_padded_sequence(encoded, input_lengths)\n",
    "        # Packed T x B x E\n",
    "        output, _ = self.rnn(packed)\n",
    "        # Packed T x B x H\n",
    "        # Important: you may need to replace '-inf' with the default zero padding for other pooling layers\n",
    "        padded, _ = torch.nn.utils.rnn.pad_packed_sequence(output, padding_value=float('-inf'))\n",
    "        # T x B x H\n",
    "        output, _ = padded.max(dim=0)\n",
    "        # B x H\n",
    "        output = self.h2o(output)\n",
    "        # B x O\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "coordinated-memorabilia",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-09T10:01:57.712222Z",
     "iopub.status.busy": "2021-04-09T10:01:57.711333Z",
     "iopub.status.idle": "2021-04-09T10:01:57.715124Z",
     "shell.execute_reply": "2021-04-09T10:01:57.714664Z"
    },
    "papermill": {
     "duration": 0.580583,
     "end_time": "2021-04-09T10:01:57.715265",
     "exception": false,
     "start_time": "2021-04-09T10:01:57.134682",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not torch.cuda.is_available():\n",
    "    print(\"WARNING: CUDA is not available. Select 'GPU On' on kernel settings\")\n",
    "device = torch.device(\"cuda\")\n",
    "torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673a1e5e",
   "metadata": {},
   "source": [
    "### Device Configuration\n",
    "Check for CUDA (GPU) availability and set up the device for training. GPU acceleration significantly speeds up the training process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "temporal-jaguar",
   "metadata": {
    "papermill": {
     "duration": 0.016346,
     "end_time": "2021-04-09T10:01:57.748923",
     "exception": false,
     "start_time": "2021-04-09T10:01:57.732577",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The **nn.CrossEntropyLoss()** criterion combines **nn.LogSoftmax()** and **nn.NLLLoss()** in one single class.  \n",
    "It is useful when training a classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "palestinian-stage",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-09T10:01:57.788707Z",
     "iopub.status.busy": "2021-04-09T10:01:57.787837Z",
     "iopub.status.idle": "2021-04-09T10:01:57.790986Z",
     "shell.execute_reply": "2021-04-09T10:01:57.790534Z"
    },
    "papermill": {
     "duration": 0.024599,
     "end_time": "2021-04-09T10:01:57.791109",
     "exception": false,
     "start_time": "2021-04-09T10:01:57.766510",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss(reduction='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "determined-needle",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-09T10:01:57.836301Z",
     "iopub.status.busy": "2021-04-09T10:01:57.835431Z",
     "iopub.status.idle": "2021-04-09T10:01:57.838493Z",
     "shell.execute_reply": "2021-04-09T10:01:57.838065Z"
    },
    "papermill": {
     "duration": 0.030527,
     "end_time": "2021-04-09T10:01:57.838613",
     "exception": false,
     "start_time": "2021-04-09T10:01:57.808086",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(model, optimizer, data, batch_size, token_size, max_norm=1, log=False):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    ncorrect = 0\n",
    "    nsentences = 0\n",
    "    ntokens = 0\n",
    "    niterations = 0\n",
    "    for batch in pool_generator(data, batch_size, token_size, shuffle=True):\n",
    "        # Get input and target sequences from batch\n",
    "        X = [torch.from_numpy(d[0]) for d in batch]\n",
    "        X_lengths = [x.numel() for x in X]\n",
    "        ntokens += sum(X_lengths)\n",
    "        X_lengths = torch.tensor(X_lengths, dtype=torch.long)\n",
    "        y = torch.tensor([d[1] for d in batch], dtype=torch.long, device=device)\n",
    "        # Pad the input sequences to create a matrix\n",
    "        X = torch.nn.utils.rnn.pad_sequence(X).to(device)\n",
    "        model.zero_grad()\n",
    "        output = model(X, X_lengths)\n",
    "        loss = criterion(output, y)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm)      # Gradient clipping https://www.kaggle.com/c/wili4/discussion/231378\n",
    "        optimizer.step()\n",
    "        # Training statistics\n",
    "        total_loss += loss.item()\n",
    "        ncorrect += (torch.max(output, 1)[1] == y).sum().item()\n",
    "        nsentences += y.numel()\n",
    "        niterations += 1\n",
    "    \n",
    "    total_loss = total_loss / nsentences\n",
    "    accuracy = 100 * ncorrect / nsentences\n",
    "    if log:\n",
    "        print(f'Train: wpb={ntokens//niterations}, bsz={nsentences//niterations}, num_updates={niterations}')\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f24587e",
   "metadata": {},
   "source": [
    "### Training Function\n",
    "Performs one epoch of training: iterates through batches, computes forward pass, calculates loss, performs backpropagation with gradient clipping, and updates model weights. Returns training accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "tired-intersection",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-09T10:01:57.880436Z",
     "iopub.status.busy": "2021-04-09T10:01:57.879641Z",
     "iopub.status.idle": "2021-04-09T10:01:57.882203Z",
     "shell.execute_reply": "2021-04-09T10:01:57.882740Z"
    },
    "papermill": {
     "duration": 0.027501,
     "end_time": "2021-04-09T10:01:57.882904",
     "exception": false,
     "start_time": "2021-04-09T10:01:57.855403",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def validate(model, data, batch_size, token_size):\n",
    "    model.eval()\n",
    "    # calculate accuracy on validation set\n",
    "    ncorrect = 0\n",
    "    nsentences = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in pool_generator(data, batch_size, token_size):\n",
    "            # Get input and target sequences from batch\n",
    "            X = [torch.from_numpy(d[0]) for d in batch]\n",
    "            X_lengths = torch.tensor([x.numel() for x in X], dtype=torch.long)\n",
    "            y = torch.tensor([d[1] for d in batch], dtype=torch.long, device=device)\n",
    "            # Pad the input sequences to create a matrix\n",
    "            X = torch.nn.utils.rnn.pad_sequence(X).to(device)\n",
    "            answer = model(X, X_lengths)\n",
    "            ncorrect += (torch.max(answer, 1)[1] == y).sum().item()\n",
    "            nsentences += y.numel()\n",
    "        dev_acc = 100 * ncorrect / nsentences\n",
    "    return dev_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d973da02",
   "metadata": {},
   "source": [
    "### Validation Function\n",
    "Evaluates the model on the validation set without updating weights (`torch.no_grad()`). Returns validation accuracy to monitor for overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "adaptive-desperate",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-09T10:01:57.921651Z",
     "iopub.status.busy": "2021-04-09T10:01:57.920761Z",
     "iopub.status.idle": "2021-04-09T10:01:57.923930Z",
     "shell.execute_reply": "2021-04-09T10:01:57.923342Z"
    },
    "papermill": {
     "duration": 0.024075,
     "end_time": "2021-04-09T10:01:57.924066",
     "exception": false,
     "start_time": "2021-04-09T10:01:57.899991",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "hidden_size = 256\n",
    "embedding_size = 64\n",
    "bidirectional = False\n",
    "ntokens = len(char_vocab)\n",
    "nlabels = len(lang_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e46ba4",
   "metadata": {},
   "source": [
    "### Model Hyperparameters\n",
    "Define the key hyperparameters: hidden layer size (256), embedding dimension (64), and whether to use bidirectional RNN. Also capture vocabulary sizes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "julian-consciousness",
   "metadata": {
    "papermill": {
     "duration": 0.017289,
     "end_time": "2021-04-09T10:01:57.958365",
     "exception": false,
     "start_time": "2021-04-09T10:01:57.941076",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Model for cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "listed-confidentiality",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-09T10:01:58.001586Z",
     "iopub.status.busy": "2021-04-09T10:01:58.000605Z",
     "iopub.status.idle": "2021-04-09T10:01:58.004104Z",
     "shell.execute_reply": "2021-04-09T10:01:58.003378Z"
    },
    "papermill": {
     "duration": 0.027812,
     "end_time": "2021-04-09T10:01:58.004293",
     "exception": false,
     "start_time": "2021-04-09T10:01:57.976481",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = CharRNNClassifier(ntokens, embedding_size, hidden_size, nlabels, bidirectional=bidirectional, pad_idx=pad_index).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    return model, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "lesser-dimension",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-09T10:01:58.048821Z",
     "iopub.status.busy": "2021-04-09T10:01:58.047923Z",
     "iopub.status.idle": "2021-04-09T10:05:02.261042Z",
     "shell.execute_reply": "2021-04-09T10:05:02.261922Z"
    },
    "papermill": {
     "duration": 184.238815,
     "end_time": "2021-04-09T10:05:02.262166",
     "exception": false,
     "start_time": "2021-04-09T10:01:58.023351",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training cross-validation model for 25 epochs\n",
      "Train: wpb=1669, bsz=2, num_updates=6035\n",
      "| epoch 001 | train accuracy=91.8% (399s)\n",
      "Train: wpb=1669, bsz=2, num_updates=6035\n",
      "| epoch 001 | train accuracy=91.8% (399s)\n",
      "| epoch 001 | valid accuracy=97.0%\n",
      "| epoch 001 | valid accuracy=97.0%\n",
      "| epoch 002 | train accuracy=97.8% (840s)\n",
      "| epoch 002 | train accuracy=97.8% (840s)\n",
      "| epoch 002 | valid accuracy=97.9%\n",
      "| epoch 002 | valid accuracy=97.9%\n",
      "| epoch 003 | train accuracy=98.4% (1265s)\n",
      "| epoch 003 | train accuracy=98.4% (1265s)\n",
      "| epoch 003 | valid accuracy=98.0%\n",
      "| epoch 003 | valid accuracy=98.0%\n",
      "| epoch 004 | train accuracy=98.7% (1695s)\n",
      "| epoch 004 | train accuracy=98.7% (1695s)\n",
      "| epoch 004 | valid accuracy=98.0%\n",
      "| epoch 004 | valid accuracy=98.0%\n",
      "| epoch 005 | train accuracy=99.0% (2118s)\n",
      "| epoch 005 | train accuracy=99.0% (2118s)\n",
      "| epoch 005 | valid accuracy=98.3%\n",
      "| epoch 005 | valid accuracy=98.3%\n",
      "| epoch 006 | train accuracy=99.2% (2541s)\n",
      "| epoch 006 | train accuracy=99.2% (2541s)\n",
      "| epoch 006 | valid accuracy=98.0%\n",
      "| epoch 006 | valid accuracy=98.0%\n",
      "| epoch 007 | train accuracy=99.4% (2964s)\n",
      "| epoch 007 | train accuracy=99.4% (2964s)\n",
      "| epoch 007 | valid accuracy=98.3%\n",
      "| epoch 007 | valid accuracy=98.3%\n",
      "| epoch 008 | train accuracy=99.5% (3393s)\n",
      "| epoch 008 | train accuracy=99.5% (3393s)\n",
      "| epoch 008 | valid accuracy=98.3%\n",
      "| epoch 008 | valid accuracy=98.3%\n",
      "| epoch 009 | train accuracy=99.7% (3820s)\n",
      "| epoch 009 | train accuracy=99.7% (3820s)\n",
      "| epoch 009 | valid accuracy=98.1%\n",
      "| epoch 009 | valid accuracy=98.1%\n",
      "| epoch 010 | train accuracy=99.8% (4243s)\n",
      "| epoch 010 | train accuracy=99.8% (4243s)\n",
      "| epoch 010 | valid accuracy=98.1%\n",
      "| epoch 010 | valid accuracy=98.1%\n",
      "| epoch 011 | train accuracy=99.8% (4660s)\n",
      "| epoch 011 | train accuracy=99.8% (4660s)\n",
      "| epoch 011 | valid accuracy=98.0%\n",
      "| epoch 011 | valid accuracy=98.0%\n",
      "| epoch 012 | train accuracy=99.8% (5082s)\n",
      "| epoch 012 | train accuracy=99.8% (5082s)\n",
      "| epoch 012 | valid accuracy=98.2%\n",
      "| epoch 012 | valid accuracy=98.2%\n",
      "| epoch 013 | train accuracy=99.9% (5524s)\n",
      "| epoch 013 | train accuracy=99.9% (5524s)\n",
      "| epoch 013 | valid accuracy=98.1%\n",
      "| epoch 013 | valid accuracy=98.1%\n",
      "| epoch 014 | train accuracy=100.0% (5972s)\n",
      "| epoch 014 | train accuracy=100.0% (5972s)\n",
      "| epoch 014 | valid accuracy=98.0%\n",
      "| epoch 014 | valid accuracy=98.0%\n",
      "| epoch 015 | train accuracy=100.0% (6366s)\n",
      "| epoch 015 | train accuracy=100.0% (6366s)\n",
      "| epoch 015 | valid accuracy=98.2%\n",
      "| epoch 015 | valid accuracy=98.2%\n",
      "| epoch 016 | train accuracy=100.0% (6748s)\n",
      "| epoch 016 | train accuracy=100.0% (6748s)\n",
      "| epoch 016 | valid accuracy=98.0%\n",
      "| epoch 016 | valid accuracy=98.0%\n",
      "| epoch 017 | train accuracy=99.9% (7132s)\n",
      "| epoch 017 | train accuracy=99.9% (7132s)\n",
      "| epoch 017 | valid accuracy=98.0%\n",
      "| epoch 017 | valid accuracy=98.0%\n",
      "| epoch 018 | train accuracy=99.9% (7514s)\n",
      "| epoch 018 | train accuracy=99.9% (7514s)\n",
      "| epoch 018 | valid accuracy=98.0%\n",
      "| epoch 018 | valid accuracy=98.0%\n",
      "| epoch 019 | train accuracy=100.0% (7900s)\n",
      "| epoch 019 | train accuracy=100.0% (7900s)\n",
      "| epoch 019 | valid accuracy=98.3%\n",
      "| epoch 019 | valid accuracy=98.3%\n",
      "| epoch 020 | train accuracy=100.0% (8288s)\n",
      "| epoch 020 | train accuracy=100.0% (8288s)\n",
      "| epoch 020 | valid accuracy=98.2%\n",
      "| epoch 020 | valid accuracy=98.2%\n",
      "| epoch 021 | train accuracy=100.0% (8674s)\n",
      "| epoch 021 | train accuracy=100.0% (8674s)\n",
      "| epoch 021 | valid accuracy=98.2%\n",
      "| epoch 021 | valid accuracy=98.2%\n",
      "| epoch 022 | train accuracy=100.0% (9094s)\n",
      "| epoch 022 | train accuracy=100.0% (9094s)\n",
      "| epoch 022 | valid accuracy=98.3%\n",
      "| epoch 022 | valid accuracy=98.3%\n",
      "| epoch 023 | train accuracy=100.0% (9737s)\n",
      "| epoch 023 | train accuracy=100.0% (9737s)\n",
      "| epoch 023 | valid accuracy=98.5%\n",
      "| epoch 023 | valid accuracy=98.5%\n",
      "| epoch 024 | train accuracy=100.0% (10114s)\n",
      "| epoch 024 | train accuracy=100.0% (10114s)\n",
      "| epoch 024 | valid accuracy=98.3%\n",
      "| epoch 024 | valid accuracy=98.3%\n",
      "| epoch 025 | train accuracy=100.0% (10496s)\n",
      "| epoch 025 | train accuracy=100.0% (10496s)\n",
      "| epoch 025 | valid accuracy=98.3%\n",
      "| epoch 025 | valid accuracy=98.3%\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "batch_size, token_size = 16, 2048\n",
    "epochs = 25\n",
    "train_accuracy = []\n",
    "valid_accuracy = []\n",
    "model, optimizer = get_model()\n",
    "print(f'Training cross-validation model for {epochs} epochs')\n",
    "t0 = time.time()\n",
    "for epoch in range(1, epochs + 1):\n",
    "    acc = train(model, optimizer, train_data, batch_size, token_size, log=epoch==1)\n",
    "    train_accuracy.append(acc)\n",
    "    print(f'| epoch {epoch:03d} | train accuracy={acc:.1f}% ({time.time() - t0:.0f}s)')\n",
    "    acc = validate(model, val_data, batch_size, token_size)\n",
    "    valid_accuracy.append(acc)\n",
    "    print(f'| epoch {epoch:03d} | valid accuracy={acc:.1f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ced4bb",
   "metadata": {},
   "source": [
    "### Training Loop\n",
    "Train the model for 25 epochs, logging training and validation accuracy after each epoch. Uses batch size of 16 and token size of 2048."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "presidential-routine",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-09T10:05:02.339057Z",
     "iopub.status.busy": "2021-04-09T10:05:02.338041Z",
     "iopub.status.idle": "2021-04-09T10:05:02.344264Z",
     "shell.execute_reply": "2021-04-09T10:05:02.343570Z"
    },
    "papermill": {
     "duration": 0.04598,
     "end_time": "2021-04-09T10:05:02.344443",
     "exception": false,
     "start_time": "2021-04-09T10:05:02.298463",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mmodel\u001b[49m)\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name, param \u001b[38;5;129;01min\u001b[39;00m model.named_parameters():\n\u001b[32m      3\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m20\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam.numel()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(param.shape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "print(model)\n",
    "for name, param in model.named_parameters():\n",
    "    print(f'{name:20} {param.numel()} {list(param.shape)}')\n",
    "print(f'TOTAL                {sum(p.numel() for p in model.parameters())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778da3c2",
   "metadata": {},
   "source": [
    "### Model Architecture Summary\n",
    "Display the model structure and count the total number of trainable parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "concrete-frontier",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-09T10:05:02.434401Z",
     "iopub.status.busy": "2021-04-09T10:05:02.433689Z",
     "iopub.status.idle": "2021-04-09T10:05:02.599120Z",
     "shell.execute_reply": "2021-04-09T10:05:02.598599Z"
    },
    "papermill": {
     "duration": 0.220858,
     "end_time": "2021-04-09T10:05:02.599270",
     "exception": false,
     "start_time": "2021-04-09T10:05:02.378412",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(1, len(train_accuracy)+1), train_accuracy)\n",
    "plt.plot(range(1, len(valid_accuracy)+1), valid_accuracy)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('Accuracy');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55521e18",
   "metadata": {},
   "source": [
    "### Visualize Training Progress\n",
    "Plot training and validation accuracy curves over epochs to assess model learning and potential overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3d14f2",
   "metadata": {},
   "source": [
    "## Save the Trained Model\n",
    "\n",
    "Save the model so you can load it later without retraining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8f1c23c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model saved to: rnn_language_model.pt\n"
     ]
    }
   ],
   "source": [
    "# Save model and vocabularies\n",
    "model_path = 'rnn_language_model.pt'\n",
    "\n",
    "# Save everything needed for inference\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'char_vocab': char_vocab,\n",
    "    'lang_vocab': lang_vocab,\n",
    "    'hidden_size': hidden_size,\n",
    "    'embedding_size': embedding_size,\n",
    "    'bidirectional': bidirectional,\n",
    "    'ntokens': ntokens,\n",
    "    'nlabels': nlabels,\n",
    "    'pad_index': pad_index,\n",
    "    'train_accuracy': train_accuracy,\n",
    "    'valid_accuracy': valid_accuracy,\n",
    "}, model_path)\n",
    "\n",
    "print(f\"✅ Model saved to: {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cece3b",
   "metadata": {},
   "source": [
    "## Inference - Predict Language for Sample Text\n",
    "\n",
    "Now that the model is trained, you can use it to predict the language of any text sample."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d326153d",
   "metadata": {},
   "source": [
    "## Load the Saved Model\n",
    "\n",
    "**Run this cell first** if you're starting a fresh notebook session and want to make predictions without retraining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f97aebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model loaded successfully from: rnn_language_model.pt\n",
      "   Vocabulary: 153 characters\n",
      "   Languages: 22 languages\n",
      "   Model ready for predictions!\n"
     ]
    }
   ],
   "source": [
    "# Load the saved model\n",
    "model_path = 'rnn_language_model.pt'\n",
    "\n",
    "# Ensure device is defined\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Check if model file exists\n",
    "if not os.path.exists(model_path):\n",
    "    print(f\"❌ Error: Model file '{model_path}' not found!\")\n",
    "    print(\"Please run the training cell and the save model cell first.\")\n",
    "else:\n",
    "    # Load checkpoint (weights_only=False to load custom Dictionary objects)\n",
    "    checkpoint = torch.load(model_path, map_location=device, weights_only=False)\n",
    "    \n",
    "    # Restore vocabularies\n",
    "    char_vocab = checkpoint['char_vocab']\n",
    "    lang_vocab = checkpoint['lang_vocab']\n",
    "    \n",
    "    # Restore model hyperparameters\n",
    "    hidden_size = checkpoint['hidden_size']\n",
    "    embedding_size = checkpoint['embedding_size']\n",
    "    bidirectional = checkpoint['bidirectional']\n",
    "    ntokens = checkpoint['ntokens']\n",
    "    nlabels = checkpoint['nlabels']\n",
    "    pad_index = checkpoint['pad_index']\n",
    "    \n",
    "    # Recreate the model\n",
    "    model = CharRNNClassifier(\n",
    "        ntokens, \n",
    "        embedding_size, \n",
    "        hidden_size, \n",
    "        nlabels, \n",
    "        bidirectional=bidirectional, \n",
    "        pad_idx=pad_index\n",
    "    ).to(device)\n",
    "    \n",
    "    # Load the trained weights\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval()  # Set to evaluation mode\n",
    "    \n",
    "    print(f\"✅ Model loaded successfully from: {model_path}\")\n",
    "    print(f\"   Vocabulary: {len(char_vocab)} characters\")\n",
    "    print(f\"   Languages: {len(lang_vocab)} languages\")\n",
    "    print(f\"   Model ready for predictions!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "126d8af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Prediction function defined!\n"
     ]
    }
   ],
   "source": [
    "def predict_language(text, model, char_vocab, lang_vocab, max_len=512):\n",
    "    \"\"\"\n",
    "    Predict the language of a given text using the trained RNN model.\n",
    "    \n",
    "    Args:\n",
    "        text: Input text string to classify\n",
    "        model: Trained CharRNNClassifier model\n",
    "        char_vocab: Character vocabulary (Dictionary object)\n",
    "        lang_vocab: Language vocabulary (Dictionary object)\n",
    "        max_len: Maximum sequence length (default 512)\n",
    "    \n",
    "    Returns:\n",
    "        predicted_language: The predicted language as a string\n",
    "        confidence: Probability/confidence of the prediction (0-1)\n",
    "        all_probs: Dictionary of all language probabilities\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Convert text to character indices\n",
    "    # Use unk_index (1) for any unknown characters\n",
    "    char_indices = []\n",
    "    for c in text[:max_len]:  # Truncate to max_len\n",
    "        idx = char_vocab.token2idx.get(c, 1)  # 1 is unk_index\n",
    "        char_indices.append(idx)\n",
    "    \n",
    "    # Convert to tensor\n",
    "    X = torch.tensor(char_indices, dtype=torch.long).unsqueeze(1).to(device)  # (seq_len, 1)\n",
    "    X_lengths = torch.tensor([len(char_indices)], dtype=torch.long)\n",
    "    \n",
    "    # Get prediction\n",
    "    with torch.no_grad():\n",
    "        output = model(X, X_lengths)  # (1, nlabels)\n",
    "        probs = F.softmax(output, dim=1).squeeze().cpu().numpy()\n",
    "    \n",
    "    # Get predicted language\n",
    "    predicted_idx = probs.argmax()\n",
    "    predicted_lang = lang_vocab.idx2token[predicted_idx]\n",
    "    confidence = float(probs[predicted_idx])\n",
    "    \n",
    "    # Create dictionary of all probabilities\n",
    "    all_probs = {lang_vocab.idx2token[i]: float(probs[i]) for i in range(len(lang_vocab))}\n",
    "    \n",
    "    return predicted_lang, confidence, all_probs\n",
    "\n",
    "print(\"✅ Prediction function defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c85f01f",
   "metadata": {},
   "source": [
    "### Prediction Function\n",
    "Converts input text to character indices, runs it through the model, and returns the predicted language with confidence scores for all classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc15ec33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔮 LANGUAGE PREDICTIONS\n",
      "======================================================================\n",
      "\n",
      "📝 Input: \"Hello, how are you doing today?\"\n",
      "   ➜ Predicted: CHINESE (confidence: 23.93%)\n",
      "   Top 3: Chinese:23.93%, Spanish:23.30%, Indonesian:17.01%\n",
      "\n",
      "📝 Input: \"Bonjour, comment allez-vous?\"\n",
      "   ➜ Predicted: CHINESE (confidence: 54.40%)\n",
      "   Top 3: Chinese:54.40%, Estonian:19.35%, Latin:16.81%\n",
      "\n",
      "📝 Input: \"Hola, ¿cómo estás?\"\n",
      "   ➜ Predicted: THAI (confidence: 48.02%)\n",
      "   Top 3: Thai:48.02%, Spanish:17.15%, Latin:11.42%\n",
      "\n",
      "📝 Input: \"Guten Tag, wie geht es Ihnen?\"\n",
      "   ➜ Predicted: INDONESIAN (confidence: 76.32%)\n",
      "   Top 3: Indonesian:76.32%, Latin:15.99%, Romanian:7.49%\n",
      "\n",
      "📝 Input: \"Ciao, come stai?\"\n",
      "   ➜ Predicted: LATIN (confidence: 62.18%)\n",
      "   Top 3: Latin:62.18%, Chinese:33.10%, Indonesian:2.32%\n",
      "\n",
      "📝 Input: \"こんにちは、元気ですか？\"\n",
      "   ➜ Predicted: CHINESE (confidence: 99.99%)\n",
      "   Top 3: Chinese:99.99%, Romanian:0.01%, Turkish:0.00%\n",
      "\n",
      "📝 Input: \"Привет, как дела?\"\n",
      "   ➜ Predicted: CHINESE (confidence: 96.82%)\n",
      "   Top 3: Chinese:96.82%, Turkish:2.67%, Romanian:0.49%\n",
      "\n",
      "📝 Input: \"你好吗？\"\n",
      "   ➜ Predicted: CHINESE (confidence: 99.61%)\n",
      "   Top 3: Chinese:99.61%, Turkish:0.18%, Indonesian:0.09%\n",
      "\n",
      "📝 Input: \"Hello, how are you doing today?\"\n",
      "   ➜ Predicted: CHINESE (confidence: 23.93%)\n",
      "   Top 3: Chinese:23.93%, Spanish:23.30%, Indonesian:17.01%\n",
      "\n",
      "📝 Input: \"Bonjour, comment allez-vous?\"\n",
      "   ➜ Predicted: CHINESE (confidence: 54.40%)\n",
      "   Top 3: Chinese:54.40%, Estonian:19.35%, Latin:16.81%\n",
      "\n",
      "📝 Input: \"Hola, ¿cómo estás?\"\n",
      "   ➜ Predicted: THAI (confidence: 48.02%)\n",
      "   Top 3: Thai:48.02%, Spanish:17.15%, Latin:11.42%\n",
      "\n",
      "📝 Input: \"Guten Tag, wie geht es Ihnen?\"\n",
      "   ➜ Predicted: INDONESIAN (confidence: 76.32%)\n",
      "   Top 3: Indonesian:76.32%, Latin:15.99%, Romanian:7.49%\n",
      "\n",
      "📝 Input: \"Ciao, come stai?\"\n",
      "   ➜ Predicted: LATIN (confidence: 62.18%)\n",
      "   Top 3: Latin:62.18%, Chinese:33.10%, Indonesian:2.32%\n",
      "\n",
      "📝 Input: \"こんにちは、元気ですか？\"\n",
      "   ➜ Predicted: CHINESE (confidence: 99.99%)\n",
      "   Top 3: Chinese:99.99%, Romanian:0.01%, Turkish:0.00%\n",
      "\n",
      "📝 Input: \"Привет, как дела?\"\n",
      "   ➜ Predicted: CHINESE (confidence: 96.82%)\n",
      "   Top 3: Chinese:96.82%, Turkish:2.67%, Romanian:0.49%\n",
      "\n",
      "📝 Input: \"你好吗？\"\n",
      "   ➜ Predicted: CHINESE (confidence: 99.61%)\n",
      "   Top 3: Chinese:99.61%, Turkish:0.18%, Indonesian:0.09%\n"
     ]
    }
   ],
   "source": [
    "# Test the prediction function with sample texts\n",
    "test_samples = [\n",
    "    \"Hello, how are you doing today?\",\n",
    "    \"Bonjour, comment allez-vous?\",\n",
    "    \"Hola, ¿cómo estás?\",\n",
    "    \"Guten Tag, wie geht es Ihnen?\",\n",
    "    \"Ciao, come stai?\",\n",
    "    \"こんにちは、元気ですか？\",\n",
    "    \"Привет, как дела?\",\n",
    "    \"你好吗？\",\n",
    "]\n",
    "\n",
    "print(\"🔮 LANGUAGE PREDICTIONS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for sample in test_samples:\n",
    "    lang, conf, all_probs = predict_language(sample, model, char_vocab, lang_vocab)\n",
    "    \n",
    "    # Get top 3 predictions\n",
    "    top_3 = sorted(all_probs.items(), key=lambda x: x[1], reverse=True)[:3]\n",
    "    \n",
    "    print(f\"\\n📝 Input: \\\"{sample}\\\"\")\n",
    "    print(f\"   ➜ Predicted: {lang.upper()} (confidence: {conf:.2%})\")\n",
    "    print(f\"   Top 3: {', '.join([f'{l}:{p:.2%}' for l, p in top_3])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfcbca44",
   "metadata": {},
   "source": [
    "### Test Predictions on Sample Texts\n",
    "Run the model on sample texts in multiple languages to verify prediction quality and display top-3 predictions for each."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b793c3",
   "metadata": {},
   "source": [
    "### Quick Prediction Function\n",
    "\n",
    "Use this simple wrapper to quickly predict the language of any text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d40f03ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🌐 Language: ENGLISH\n",
      "📊 Confidence: 56.54%\n",
      "\n",
      "📈 Top 5 predictions:\n",
      "   1. English         ████████████████ 56.54%\n",
      "   2. Pushto          ██████████ 33.94%\n",
      "   3. Latin           ██ 8.62%\n",
      "   4. Russian          0.34%\n",
      "   5. Portugese        0.30%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('English', 0.5653689503669739)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def quick_predict(text):\n",
    "    \"\"\"\n",
    "    Quick prediction function - just pass your text!\n",
    "    \n",
    "    Usage:\n",
    "        quick_predict(\"Your text here\")\n",
    "    \"\"\"\n",
    "    lang, conf, all_probs = predict_language(text, model, char_vocab, lang_vocab)\n",
    "    \n",
    "    print(f\"🌐 Language: {lang.upper()}\")\n",
    "    print(f\"📊 Confidence: {conf:.2%}\")\n",
    "    print(f\"\\n📈 Top 5 predictions:\")\n",
    "    \n",
    "    # Sort and display top 5\n",
    "    top_5 = sorted(all_probs.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "    for i, (language, prob) in enumerate(top_5, 1):\n",
    "        bar = \"█\" * int(prob * 30)\n",
    "        print(f\"   {i}. {language:15} {bar} {prob:.2%}\")\n",
    "    \n",
    "    return lang, conf\n",
    "\n",
    "# Try it yourself! Change the text below:\n",
    "quick_predict(\"Machine learning is fascinating and powerful and is transforming the world. I think it will have a huge impact on many industries and aspects of our lives. We should all pay attention to its developments. One day, it might even surpass human intelligence in certain areas. The possibilities are endless and exciting! why wont you give me cyka blyat oh my god this is so cool I love programming and AI so much I can't wait to see what the future holds for us all what the hell is Pushto is that a language oh now it says English okay bro i guess. I think it will have a huge impact on many industries and aspects of our lives. We should all pay attention to its developments. One day, it might even surpass human intelligence in certain areas. The possibilities are endless and exciting! why wont you give me cyka blyat oh my god this is so cool I love programming and AI so much I can't wait to see what the future holds for us all what the hell is Pushto is that a language oh now it says English okay bro i guessI think it will have a huge impact on many industries and aspects of our lives. We should all pay attention to its developments. One day, it might even surpass human intelligence in certain areas. The possibilities are endless and exciting! why wont you give me cyka blyat oh my god this is so cool I love programming and AI so much I can't wait to see what the future holds for us all what the hell is Pushto is that a language oh now it says English okay bro i guessI think it will have a huge impact on many industries and aspects of our lives. We should all pay attention to its developments. One day, it might even surpass human intelligence in certain areas. The possibilities are endless and exciting! why wont you give me cyka blyat oh my god this is so cool I love programming and AI so much I can't wait to see what the future holds for us all what the hell is Pushto is that a language oh now it says English okay bro i guess I think it will have a huge impact on many industries and aspects of our lives. We should all pay attention to its developments. One day, it might even surpass human intelligence in certain areas. The possibilities are endless and exciting! why wont you give me cyka blyat oh my god this is so cool I love programming and AI so much I can't wait to see what the future holds for us all what the hell is Pushto is that a language oh now it says English okay bro i guessI think it will have a huge impact on many industries and aspects of our lives. We should all pay attention to its developments. One day, it might even surpass human intelligence in certain areas. The possibilities are endless and exciting! why wont you give me cyka blyat oh my god this is so cool I love programming and AI so much I can't wait to see what the future holds for us all what the hell is Pushto is that a language oh now it says English okay bro i guessI think it will have a huge impact on many industries and aspects of our lives. We should all pay attention to its developments. One day, it might even surpass human intelligence in certain areas. The possibilities are endless and exciting! why wont you give me cyka blyat oh my god this is so cool I love programming and AI so much I can't wait to see what the future holds for us all what the hell is Pushto is that a language oh now it says English okay bro i guessI think it will have a huge impact on many industries and aspects of our lives. We should all pay attention to its developments. One day, it might even surpass human intelligence in certain areas. The possibilities are endless and exciting! why wont you give me cyka blyat oh my god this is so cool I love programming and AI so much I can't wait to see what the future holds for us all what the hell is Pushto is that a language oh now it says English okay bro i guessI think it will have a huge impact on many industries and aspects of our lives. We should all pay attention to its developments. One day, it might even surpass human intelligence in certain areas. The possibilities are endless and exciting! why wont you give me cyka blyat oh my god this is so cool I love programming and AI so much I can't wait to see what the future holds for us all what the hell is Pushto is that a language oh now it says English okay bro i guessI think it will have a huge impact on many industries and aspects of our lives. We should all pay attention to its developments. One day, it might even surpass human intelligence in certain areas. The possibilities are endless and exciting! why wont you give me cyka blyat oh my god this is so cool I love programming and AI so much I can't wait to see what the future holds for us all what the hell is Pushto is that a language oh now it says English okay bro i guessI think it will have a huge impact on many industries and aspects of our lives. We should all pay attention to its developments. One day, it might even surpass human intelligence in certain areas. The possibilities are endless and exciting! why wont you give me cyka blyat oh my god this is so cool I love programming and AI so much I can't wait to see what the future holds for us all what the hell is Pushto is that a language oh now it says English okay bro i guessI think it will have a huge impact on many industries and aspects of our lives. We should all pay attention to its developments. One day, it might even surpass human intelligence in certain areas. The possibilities are endless and exciting! why wont you give me cyka blyat oh my god this is so cool I love programming and AI so much I can't wait to see what the future holds for us all what the hell is Pushto is that a language oh now it says English okay bro i guessI think it will have a huge impact on many industries and aspects of our lives. We should all pay attention to its developments. One day, it might even surpass human intelligence in certain areas. The possibilities are endless and exciting! why wont you give me cyka blyat oh my god this is so cool I love programming and AI so much I can't wait to see what the future holds for us all what the hell is Pushto is that a language oh now it says English okay bro i guessI think it will have a huge impact on many industries and aspects of our lives. We should all pay attention to its developments. One day, it might even surpass human intelligence in certain areas. The possibilities are endless and exciting! why wont you give me cyka blyat oh my god this is so cool I love programming and AI so much I can't wait to see what the future holds for us all what the hell is Pushto is that a language oh now it says English okay bro i guessI think it will have a huge impact on many industries and aspects of our lives. We should all pay attention to its developments. One day, it might even surpass human intelligence in certain areas. The possibilities are endless and exciting! why wont you give me cyka blyat oh my god this is so cool I love programming and AI so much I can't wait to see what the future holds for us all what the hell is Pushto is that a language oh now it says English okay bro i guess\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a285806b",
   "metadata": {},
   "source": [
    "## 🔍 Diagnosis: Character Encoding Issue\n",
    "\n",
    "The predictions are off because the training data has **character encoding corruption** (mojibake). Let's investigate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f69fb4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 SAMPLE FROM TRAINING DATA:\n",
      "================================================================================\n",
      "Language: Estonian\n",
      "Text preview (first 200 chars):\n",
      "klement gottwaldi surnukeha palsameeriti ning paigutati mausoleumi surnukeha oli aga liiga hilja ja oskamatult palsameeritud ning hakkas ilmutama lagunemise tundemÃ¤rke  aastal viidi ta surnukeha maus\n",
      "\n",
      "🔤 CHARACTER VOCABULARY SAMPLE:\n",
      "================================================================================\n",
      "Total characters in vocab: 153\n",
      "First 50 characters: ['<pad>', '<unk>', ' ', '\"', '#', '$', '*', '-', '<', '>', '?', '[', '\\\\', ']', '^', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '{', '|', '}', '~', '\\x80', '\\x81', '\\x82', '\\x83']\n",
      "\n",
      "⚠️  Suspicious characters (potential encoding issues): 104\n",
      "Examples: ['\\x80', '\\x81', '\\x82', '\\x83', '\\x84', '\\x85', '\\x86', '\\x87', '\\x88', '\\x89', '\\x8a', '\\x8b', '\\x8c', '\\x8d', '\\x8e', '\\x8f', '\\x90', '\\x91', '\\x92', '\\x93', '\\x94', '\\x95', '\\x96', '\\x97', '\\x98', '\\x99', '\\x9a', '\\x9b', '\\x9c', '\\x9d']\n"
     ]
    }
   ],
   "source": [
    "# Check a sample from the training data\n",
    "print(\"📊 SAMPLE FROM TRAINING DATA:\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Language: {y_train_full[0]}\")\n",
    "print(f\"Text preview (first 200 chars):\\n{x_train_full[0][:200]}\")\n",
    "print()\n",
    "\n",
    "# Check what characters are in the vocabulary\n",
    "print(\"🔤 CHARACTER VOCABULARY SAMPLE:\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Total characters in vocab: {len(char_vocab)}\")\n",
    "print(f\"First 50 characters: {char_vocab.idx2token[:50]}\")\n",
    "print()\n",
    "\n",
    "# Check for encoding issues (skip special tokens like <pad>, <unk>)\n",
    "suspicious_chars = [char for char in char_vocab.idx2token if len(char) == 1 and ord(char) > 127 and char not in ['à', 'é', 'ñ', 'ü', 'ö', 'ä']]\n",
    "print(f\"⚠️  Suspicious characters (potential encoding issues): {len(suspicious_chars)}\")\n",
    "print(f\"Examples: {suspicious_chars[:30]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec2b5d9",
   "metadata": {},
   "source": [
    "### 💡 The Problem & Solution\n",
    "\n",
    "**Root Cause:** The dataset file `dataset.csv` has character encoding issues (mojibake). When pandas reads it without specifying the correct encoding, special characters get corrupted:\n",
    "- `é` → `Ã©`\n",
    "- `–` → `â€\"`\n",
    "- Thai/Chinese/Japanese characters get garbled\n",
    "\n",
    "This means:\n",
    "1. The model was trained on **corrupted text**\n",
    "2. It learned to recognize languages based on **wrong character patterns**\n",
    "3. When you feed it **clean text** for prediction, it doesn't match what it learned\n",
    "\n",
    "**Solution:** Re-load the dataset with the correct encoding and retrain the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "010f2158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 TESTING DIFFERENT ENCODINGS:\n",
      "================================================================================\n",
      "\n",
      "✅ Encoding: utf-8\n",
      "   Sample text: klement gottwaldi surnukeha palsameeriti ning paigutati mausoleumi surnukeha oli aga liiga hilja ja oskamatult palsameeritud ning hakkas ilmutama lagunemise tundemärke  aastal viidi ta surnukeha mausoleumist ära ja kremeeriti zlíni linn kandis aastatel – nime gottwaldov ukrainas harkivi oblastis kandis zmiivi linn aastatel – nime gotvald\n",
      "\n",
      "✅ Encoding: latin-1\n",
      "   Sample text: klement gottwaldi surnukeha palsameeriti ning paigutati mausoleumi surnukeha oli aga liiga hilja ja oskamatult palsameeritud ning hakkas ilmutama lagunemise tundemÃ¤rke  aastal viidi ta surnukeha mausoleumist Ã¤ra ja kremeeriti zlÃ­ni linn kandis aastatel â nime gottwaldov ukrainas harkivi oblastis kandis zmiivi linn aastatel â nime gotvald\n",
      "\n",
      "✅ Encoding: iso-8859-1\n",
      "   Sample text: klement gottwaldi surnukeha palsameeriti ning paigutati mausoleumi surnukeha oli aga liiga hilja ja oskamatult palsameeritud ning hakkas ilmutama lagunemise tundemÃ¤rke  aastal viidi ta surnukeha mausoleumist Ã¤ra ja kremeeriti zlÃ­ni linn kandis aastatel â nime gottwaldov ukrainas harkivi oblastis kandis zmiivi linn aastatel â nime gotvald\n",
      "\n",
      "❌ Encoding: cp1252 - Failed: 'charmap' codec can't decode byte 0x8d in position\n",
      "\n",
      "================================================================================\n",
      "💡 Compare the sample texts above with the original.\n",
      "   Choose the encoding that shows clean, readable characters.\n"
     ]
    }
   ],
   "source": [
    "# FIX: Load the dataset with the correct encoding\n",
    "# Common encodings to try: 'utf-8', 'latin-1', 'iso-8859-1', 'cp1252'\n",
    "\n",
    "print(\"🔧 TESTING DIFFERENT ENCODINGS:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "encodings_to_try = ['utf-8', 'latin-1', 'iso-8859-1', 'cp1252']\n",
    "\n",
    "for enc in encodings_to_try:\n",
    "    try:\n",
    "        test_df = pd.read_csv(f'{INPUTDIR}/dataset.csv', encoding=enc, nrows=50)\n",
    "        print(f\"\\n✅ Encoding: {enc}\")\n",
    "        print(f\"   Sample text: {test_df['Text'][0][:3000]}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ Encoding: {enc} - Failed: {str(e)[:50]}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"💡 Compare the sample texts above with the original.\")\n",
    "print(\"   Choose the encoding that shows clean, readable characters.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed0701b",
   "metadata": {},
   "source": [
    "### 🔨 Fixed Data Loading\n",
    "\n",
    "Replace the original data loading cell with this corrected version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b140c2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CORRECTED: Load data with proper encoding\n",
    "# Try different encodings until you find the one that works\n",
    "# Common options: 'latin-1', 'iso-8859-1', 'cp1252', 'utf-8'\n",
    "\n",
    "raw_fixed = pd.read_csv(f'{INPUTDIR}/dataset.csv', encoding='latin-1')\n",
    "x_train_full_fixed = raw_fixed['Text']\n",
    "y_train_full_fixed = raw_fixed['language']\n",
    "\n",
    "print('✅ FIXED DATA EXAMPLE:')\n",
    "print('LANG =', y_train_full_fixed[0])\n",
    "print('TEXT =', x_train_full_fixed[0][:200])\n",
    "print()\n",
    "print(f\"Total samples: {len(x_train_full_fixed)}\")\n",
    "print(f\"Languages: {sorted(set(y_train_full_fixed))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac819ae0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 📋 Summary: How to Fix the Predictions\n",
    "\n",
    "### The Issue\n",
    "Your model's predictions are inaccurate because the training data has **character encoding corruption**. When the CSV was loaded with `pd.read_csv()` without specifying encoding, characters got misinterpreted:\n",
    "- Accented characters (é, ñ, ü) became gibberish (Ã©, Ã±, Ã¼)\n",
    "- Non-Latin scripts (Thai, Chinese, Japanese) got completely garbled\n",
    "\n",
    "The model learned patterns from **corrupted text**, so it fails on **clean text**.\n",
    "\n",
    "### The Fix (3 Steps)\n",
    "\n",
    "**Step 1: Run the diagnosis cells above** to:\n",
    "- Confirm the encoding issue in your current training data\n",
    "- Test different encodings to find the right one\n",
    "\n",
    "**Step 2: Fix the data loading** (modify the first cell):\n",
    "```python\n",
    "# OLD (wrong):\n",
    "raw = pd.read_csv(f'{INPUTDIR}/dataset.csv')\n",
    "\n",
    "# NEW (correct):\n",
    "raw = pd.read_csv(f'{INPUTDIR}/dataset.csv', encoding='latin-1')  # or whichever encoding works\n",
    "```\n",
    "\n",
    "**Step 3: Retrain the model**:\n",
    "- Re-run all cells from the beginning with the fixed data loading\n",
    "- The vocabularies will be rebuilt with correct characters\n",
    "- The model will learn from clean text\n",
    "- Save the new model using the save cell\n",
    "\n",
    "### Quick Test\n",
    "After fixing, compare:\n",
    "- **Before:** `predict_language(\"Bonjour\")` might give wrong results\n",
    "- **After:** Should correctly identify French with high confidence\n",
    "\n",
    "### Alternative Quick Fix\n",
    "If you can't retrain right now, you could try applying the same encoding corruption to your test text before prediction (not recommended for production, but useful for testing the current model)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 201.070608,
   "end_time": "2021-04-09T10:05:04.797692",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-04-09T10:01:43.727084",
   "version": "2.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
