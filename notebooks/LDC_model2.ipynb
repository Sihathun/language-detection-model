{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38f32768",
   "metadata": {},
   "source": [
    "## ROUND 2 BABYY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523e6a87",
   "metadata": {},
   "source": [
    "### Import Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85f9ced8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ UTF-8 encoding enabled\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>klement gottwaldi surnukeha palsameeriti ning ...</td>\n",
       "      <td>Estonian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sebes joseph pereira thomas  på eng the jesuit...</td>\n",
       "      <td>Swedish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ถนนเจริญกรุง อักษรโรมัน thanon charoen krung เ...</td>\n",
       "      <td>Thai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>விசாகப்பட்டினம் தமிழ்ச்சங்கத்தை இந்துப் பத்திர...</td>\n",
       "      <td>Tamil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>de spons behoort tot het geslacht haliclona en...</td>\n",
       "      <td>Dutch</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  language\n",
       "0  klement gottwaldi surnukeha palsameeriti ning ...  Estonian\n",
       "1  sebes joseph pereira thomas  på eng the jesuit...   Swedish\n",
       "2  ถนนเจริญกรุง อักษรโรมัน thanon charoen krung เ...      Thai\n",
       "3  விசாகப்பட்டினம் தமிழ்ச்சங்கத்தை இந்துப் பத்திர...     Tamil\n",
       "4  de spons behoort tot het geslacht haliclona en...     Dutch"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Force UTF-8 encoding for file operations\n",
    "os.environ['PYTHONIOENCODING'] = 'utf-8'\n",
    "\n",
    "# For Jupyter notebooks, this is sufficient\n",
    "import locale\n",
    "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
    "\n",
    "print(\"✅ UTF-8 encoding enabled\")\n",
    "\n",
    "\n",
    "data_path = os.path.join('..', 'data', 'raw', 'dataset.csv')\n",
    "df = pd.read_csv(data_path, encoding='utf-8')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ef3728",
   "metadata": {},
   "source": [
    "### Code tat does sth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e71bfa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>klement gottwaldi surnukeha palsameeriti ning ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sebes joseph pereira thomas  på eng the jesuit...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ถนนเจริญกรุง อักษรโรมัน thanon charoen krung เ...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>விசாகப்பட்டினம் தமிழ்ச்சங்கத்தை இந்துப் பத்திர...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>de spons behoort tot het geslacht haliclona en...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  language\n",
       "0  klement gottwaldi surnukeha palsameeriti ning ...         4\n",
       "1  sebes joseph pereira thomas  på eng the jesuit...        17\n",
       "2  ถนนเจริญกรุง อักษรโรมัน thanon charoen krung เ...        19\n",
       "3  விசாகப்பட்டினம் தமிழ்ச்சங்கத்தை இந்துப் பத்திர...        18\n",
       "4  de spons behoort tot het geslacht haliclona en...         2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder=LabelEncoder()\n",
    "df['language']=encoder.fit_transform(df['language'])\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06e149a",
   "metadata": {},
   "source": [
    "### Lang count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f8f8181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(df['language'].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1692244",
   "metadata": {},
   "source": [
    "### Joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "802f658d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['encoder_target.joblib']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib \n",
    "joblib.dump(encoder,'encoder_target.joblib')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921b4c4e",
   "metadata": {},
   "source": [
    "### Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25086a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "data,test = train_test_split(df,test_size=0.15,stratify=df['language'])\n",
    "train,val = train_test_split(df,test_size=0.15,stratify=df['language'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6277e03",
   "metadata": {},
   "source": [
    "### Code that does sth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b816c5a",
   "metadata": {},
   "source": [
    "### Install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24761134",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, Bidirectional,Dropout,TextVectorization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15add9cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\Desktop\\KIT Y2\\Semester 2\\Deep Learning with Python\\Projects\\DL-Lang-Detect\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "MAX_WORD=5000\n",
    "MAX_LEN=200\n",
    "vectorizer = TextVectorization(\n",
    "    max_tokens=MAX_WORD,\n",
    "    output_sequence_length=MAX_LEN,\n",
    "    output_mode=\"int\"\n",
    ")\n",
    "\n",
    "vectorizer.adapt(train['Text'])\n",
    "\n",
    "model=Sequential(\n",
    "    [vectorizer,\n",
    "     Embedding(input_dim=MAX_WORD,output_dim=128,input_length=MAX_LEN),\n",
    "     Bidirectional(LSTM(128)),\n",
    "     Dropout(0.3),\n",
    "     Dense(64,activation='relu'),\n",
    "     Dense(22,activation='softmax')   \n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b61fa663",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_train = train['Text'].astype(str).to_numpy()\n",
    "y_train = train['language'].astype('int32').to_numpy()\n",
    "\n",
    "x_val = val['Text'].astype(str).to_numpy()\n",
    "y_val = val['language'].astype('int32').to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c9c39ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3300,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y_val.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dcec46a",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2a99068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 348ms/step - accuracy: 0.4745 - loss: 1.6328 - val_accuracy: 0.8000 - val_loss: 0.5822 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 270ms/step - accuracy: 0.8850 - loss: 0.3506 - val_accuracy: 0.8833 - val_loss: 0.3641 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 323ms/step - accuracy: 0.9072 - loss: 0.2665 - val_accuracy: 0.7812 - val_loss: 0.6767 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 296ms/step - accuracy: 0.9101 - loss: 0.2576 - val_accuracy: 0.9221 - val_loss: 0.2206 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 296ms/step - accuracy: 0.9303 - loss: 0.1719 - val_accuracy: 0.9218 - val_loss: 0.2193 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 294ms/step - accuracy: 0.9337 - loss: 0.1566 - val_accuracy: 0.9233 - val_loss: 0.2374 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 330ms/step - accuracy: 0.9361 - loss: 0.1463 - val_accuracy: 0.9264 - val_loss: 0.2139 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 292ms/step - accuracy: 0.9391 - loss: 0.1316 - val_accuracy: 0.9285 - val_loss: 0.2197 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 321ms/step - accuracy: 0.9410 - loss: 0.1245 - val_accuracy: 0.9273 - val_loss: 0.2155 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 301ms/step - accuracy: 0.9421 - loss: 0.1211 - val_accuracy: 0.9306 - val_loss: 0.2249 - learning_rate: 0.0010\n",
      "Epoch 11/20\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 293ms/step - accuracy: 0.9427 - loss: 0.1155 - val_accuracy: 0.9282 - val_loss: 0.2437 - learning_rate: 0.0010\n",
      "Epoch 12/20\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 290ms/step - accuracy: 0.9428 - loss: 0.1159 - val_accuracy: 0.9224 - val_loss: 0.2652 - learning_rate: 0.0010\n",
      "Epoch 13/20\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 281ms/step - accuracy: 0.9476 - loss: 0.1068 - val_accuracy: 0.9315 - val_loss: 0.2337 - learning_rate: 1.0000e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 288ms/step - accuracy: 0.9475 - loss: 0.1004 - val_accuracy: 0.9303 - val_loss: 0.2377 - learning_rate: 1.0000e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 286ms/step - accuracy: 0.9476 - loss: 0.0999 - val_accuracy: 0.9303 - val_loss: 0.2425 - learning_rate: 1.0000e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 299ms/step - accuracy: 0.9496 - loss: 0.0978 - val_accuracy: 0.9273 - val_loss: 0.2454 - learning_rate: 1.0000e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 292ms/step - accuracy: 0.9484 - loss: 0.0964 - val_accuracy: 0.9306 - val_loss: 0.2518 - learning_rate: 1.0000e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 289ms/step - accuracy: 0.9506 - loss: 0.0957 - val_accuracy: 0.9303 - val_loss: 0.2516 - learning_rate: 1.0000e-05\n",
      "Epoch 19/20\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 308ms/step - accuracy: 0.9491 - loss: 0.0949 - val_accuracy: 0.9300 - val_loss: 0.2516 - learning_rate: 1.0000e-05\n",
      "Epoch 20/20\n",
      "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 294ms/step - accuracy: 0.9502 - loss: 0.0955 - val_accuracy: 0.9297 - val_loss: 0.2520 - learning_rate: 1.0000e-05\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from tensorflow.keras.optimizers import AdamW\n",
    "from tensorflow.keras.callbacks  import EarlyStopping,ReduceLROnPlateau,ModelCheckpoint\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "model.compile(optimizer=AdamW(learning_rate=1e-3),\n",
    "           loss='sparse_categorical_crossentropy'   \n",
    "              ,metrics=['accuracy'])\n",
    "\n",
    "early=EarlyStopping(monitor='val_loss',patience=5,mode='min')\n",
    "reduceLr=ReduceLROnPlateau(monitor='val_loss',patience=5,min_lr=1e-5,mode='min')\n",
    "history=model.fit(x_train,y_train,validation_data=(x_val,y_val),batch_size=64,epochs=20,callbacks=[reduceLr])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a861c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = test['Text'].astype(str).to_numpy()\n",
    "y_test= test['language'].astype('int32').to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "119d73bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 47ms/step - accuracy: 0.9485 - loss: 0.1274\n"
     ]
    }
   ],
   "source": [
    "metrics=model.evaluate(x_test,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3d7c83c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9484848380088806\n",
      "\n",
      "Loss: 0.12737073004245758\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f'Accuracy: {metrics[1]}',end='\\n\\n')\n",
    "print(f'Loss: {metrics[0]}',end='\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6c443f36",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeEncodeError",
     "evalue": "'charmap' codec can't encode character '\\u062f' in position 29: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnicodeEncodeError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmodel_language_identification.keras\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\Desktop\\KIT Y2\\Semester 2\\Deep Learning with Python\\Projects\\DL-Lang-Detect\\.venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\encodings\\cp1252.py:19\u001b[39m, in \u001b[36mIncrementalEncoder.encode\u001b[39m\u001b[34m(self, input, final)\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mencode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, final=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcodecs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcharmap_encode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43mencoding_table\u001b[49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m]\n",
      "\u001b[31mUnicodeEncodeError\u001b[39m: 'charmap' codec can't encode character '\\u062f' in position 29: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "model.save('model_language_identification.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ed5a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming 'history' is the variable storing the training history\n",
    "metrics = ['loss','accuracy']\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    plt.subplot(2, 3, i + 1)  # 2 rows, 3 columns of plots\n",
    "    plt.plot(history.history[metric], label='Train')\n",
    "    plt.plot(history.history['val_' + metric], label='Validation')\n",
    "    plt.title(metric.capitalize())\n",
    "    plt.ylabel(metric.capitalize())\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(loc='best')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c5443e",
   "metadata": {},
   "source": [
    "### Lang Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea99764e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from joblib import load\n",
    "model=load_model('/kaggle/input/model-and-encoder/tensorflow2/default/1/model_language_identification.keras')\n",
    "encoder=load('/kaggle/input/model-and-encoder/tensorflow2/default/1/encoder_target.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f563539",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow import constant\n",
    "import numpy as np\n",
    "texts=constant(['''Chaque matin, je me lève tôt pour me promener dans le parc près de chez moi. J'aime écouter le chant des oiseaux et sentir la fraîcheur de l'air. C'est un moment de calme qui me permet de commencer la journée en paix. Ensuite, je prends un petit déjeuner léger avant de commencer mon travail. Ce petit rituel m'aide à rester concentré et de bonne humeur toute la journée.''',\n",
    "                              '''كل صباح، أستيقظ مبكرًا لأتمشى في الحديقة القريبة من منزلي. أحب الاستماع إلى زقزقة العصافير واستنشاق نسمات الهواء العليل. إنها لحظة هادئة تساعدني على بدء يومي بسلام. بعد ذلك، أتناول فطورًا خفيفًا قبل أن أبدأ عملي. هذا الروتين الصغير يساعدني على البقاء مركزًا وبمزاج جيد طوال اليوم.'''])\n",
    "y_pred=model.predict(texts)\n",
    "predicted_indices = np.argmax(y_pred, axis=1)\n",
    "labels = encoder.inverse_transform(predicted_indices)\n",
    "\n",
    "for text, label in zip(texts, labels):\n",
    "    print(\"Language prediction:\", label)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
